@misc{StricklandNgUnbiggenAI2022,
  author       = {Eliza Strickland},
  title        = {Andrew Ng: Unbiggen {AI}},
  howpublished = {IEEE Spectrum},
  year         = {2022},
  month        = feb,
  url          = {https://spectrum.ieee.org/andrew-ng-data-centric-ai},
  note         = {Published 09 Feb 2022; accessed 15 Jan 2026. This article appears in the April 2022 print issue as ``Andrew Ng, AI Minimalist.''}
}

@article{Renier2016,
  abstract  = {Understanding how neural information is processed in physiological and pathological states would benefit from precise detection, localization, and quantification of the activity of all neurons across the entire brain, which has not, to date, been achieved in the mammalian brain. We introduce a pipeline for high-speed acquisition of brain activity at cellular resolution through profiling immediate early gene expression using immunostaining and light-sheet fluorescence imaging, followed by automated mapping and analysis of activity by an open-source software program we term ClearMap. We validate the pipeline first by analysis of brain regions activated in response to haloperidol. Next, we report new cortical regions downstream of whisker-evoked sensory processing during active exploration. Last, we combine activity mapping with axon tracing to uncover new brain regions differentially activated during parenting behavior. This pipeline is widely applicable to different experimental paradigms, including animal species for which transgenic activity reporters are not readily available.},
  author    = {Nicolas Renier and Eliza L. Adams and Christoph Kirst and Zhuhao Wu and Ricardo Azevedo and Johannes Kohl and Anita E. Autry and Lolahon Kadiri and Kannan Umadevi Venkataraju and Yu Zhou and Victoria X. Wang and Cheuk Y. Tang and Olav Olsen and Catherine Dulac and Pavel Osten and Marc Tessier-Lavigne},
  doi       = {10.1016/j.cell.2016.05.007},
  issn      = {10974172},
  issue     = {7},
  journal   = {Cell},
  month     = {6},
  pages     = {1789-1802},
  pmid      = {27238021},
  publisher = {Cell Press},
  title     = {Mapping of Brain Activity by Automated Volume Analysis of Immediate Early Genes},
  volume    = {165},
  year      = {2016}
}
@article{Kaltenecker2024,
  abstract  = {Automated detection of specific cells in three-dimensional datasets such as whole-brain light-sheet image stacks is challenging. Here, we present DELiVR, a virtual reality-trained deep-learning pipeline for detecting c-Fos+ cells as markers for neuronal activity in cleared mouse brains. Virtual reality annotation substantially accelerated training data generation, enabling DELiVR to outperform state-of-the-art cell-segmenting approaches. Our pipeline is available in a user-friendly Docker container that runs with a standalone Fiji plugin. DELiVR features a comprehensive toolkit for data visualization and can be customized to other cell types of interest, as we did here for microglia somata, using Fiji for dataset-specific training. We applied DELiVR to investigate cancer-related brain activity, unveiling an activation pattern that distinguishes weight-stable cancer from cancers associated with weight loss. Overall, DELiVR is a robust deep-learning tool that does not require advanced coding skills to analyze whole-brain imaging data in health and disease.},
  author    = {Doris Kaltenecker and Rami Al-Maskari and Moritz Negwer and Luciano Hoeher and Florian Kofler and Shan Zhao and Mihail Todorov and Zhouyi Rong and Johannes Christian Paetzold and Benedikt Wiestler and Marie Piraud and Daniel Rueckert and Julia Geppert and Pauline Morigny and Maria Rohm and Bjoern H. Menze and Stephan Herzig and Mauricio Berriel Diaz and Ali Ertürk},
  doi       = {10.1038/s41592-024-02245-2},
  issn      = {15487105},
  issue     = {7},
  journal   = {Nature Methods},
  month     = {7},
  pages     = {1306-1315},
  pmid      = {38649742},
  publisher = {Nature Research},
  title     = {Virtual reality-empowered deep-learning analysis of brain cells},
  volume    = {21},
  year      = {2024}
}
@article{Seiriki2017,
  abstract  = {Subcellular resolution imaging of the whole brain and subsequent image analysis are prerequisites for understanding anatomical and functional brain networks. Here, we have developed a very high-speed serial-sectioning imaging system named FAST (block-face serial microscopy tomography), which acquires high-resolution images of a whole mouse brain in a speed range comparable to that of light-sheet fluorescence microscopy. FAST enables complete visualization of the brain at a resolution sufficient to resolve all cells and their subcellular structures. FAST renders unbiased quantitative group comparisons of normal and disease model brain cells for the whole brain at a high spatial resolution. Furthermore, FAST is highly scalable to non-human primate brains and human postmortem brain tissues, and can visualize neuronal projections in a whole adult marmoset brain. Thus, FAST provides new opportunities for global approaches that will allow for a better understanding of brain systems in multiple animal models and in human diseases. Seiriki et al. developed a very high-speed serial-sectioning imaging system named FAST that allows whole-brain imaging at a spatial resolution to image all brain cells and long-range neuronal projections in experimental animal models and facilitates animal-to-human translational research.},
  author    = {Kaoru Seiriki and Atsushi Kasai and Takeshi Hashimoto and Wiebke Schulze and Misaki Niu and Shun Yamaguchi and Takanobu Nakazawa and Ken ichi Inoue and Shiori Uezono and Masahiko Takada and Yuichiro Naka and Hisato Igarashi and Masato Tanuma and James A. Waschek and Yukio Ago and Kenji F. Tanaka and Atsuko Hayata-Takano and Kazuki Nagayasu and Norihito Shintani and Ryota Hashimoto and Yasuto Kunii and Mizuki Hino and Junya Matsumoto and Hirooki Yabe and Takeharu Nagai and Katsumasa Fujita and Toshio Matsuda and Kazuhiro Takuma and Akemichi Baba and Hitoshi Hashimoto},
  doi       = {10.1016/j.neuron.2017.05.017},
  issn      = {10974199},
  issue     = {6},
  journal   = {Neuron},
  keywords  = {cell distribution,human post-mortem brain,non-human primate brain,subcellular resolution,whole-brain imaging},
  month     = {6},
  pages     = {1085-1100.e6},
  pmid      = {28641108},
  publisher = {Cell Press},
  title     = {High-Speed and Scalable Whole-Brain Imaging in Rodents and Primates},
  volume    = {94},
  year      = {2017}
}
@article{Renier2014,
  abstract  = {The visualization of molecularly labeled structures within large intact tissues in three dimensions is an area of intense focus. We describe a simple, rapid, and inexpensive method, iDISCO, that permits whole-mount immunolabeling with volume imaging of large cleared samples ranging from perinatal mouse embryos to adult organs, such as brains or kidneys. iDISCO is modeled on classical histology techniques, facilitating translation of section staining assays to intact tissues, as evidenced by compatibility with 28 antibodies to both endogenous antigens and transgenic reporters like GFP. When applied to degenerating neurons, iDISCO revealed unexpected variability in number of apoptotic neurons within individual sensory ganglia despite tight control of total number in all ganglia. It also permitted imaging of single degenerating axons in adult brain and the first visualization of cleaved Caspase-3 in degenerating embryonic sensory axons in vivo, even single axons. iDISCO enables facile volume imaging of immunolabeled structures in complex tissues. PaperClip},
  author    = {Nicolas Renier and Zhuhao Wu and David J. Simon and Jing Yang and Pablo Ariel and Marc Tessier-Lavigne},
  doi       = {10.1016/j.cell.2014.10.010},
  issn      = {10974172},
  issue     = {4},
  journal   = {Cell},
  month     = {11},
  pages     = {896-910},
  pmid      = {25417164},
  publisher = {Cell Press},
  title     = {IDISCO: A simple, rapid method to immunolabel large tissue samples for volume imaging},
  volume    = {159},
  year      = {2014}
}
@article{Chung2013,
  abstract = {Obtaining high-resolution information from a complex system, while maintaining the global perspective needed to understand system function, represents a key challenge in biology. Here we address this challenge with a method (termed CLARITY) for the transformation of intact tissue into a nanoporous hydrogel-hybridized form (crosslinked to a three-dimensional network of hydrophilic polymers) that is fully assembled but optically transparent and macromolecule-permeable. Using mouse brains, we show intact-tissue imaging of long-range projections, local circuit wiring, cellular relationships, subcellular structures, protein complexes, nucleic acids and neurotransmitters. CLARITY also enables intact-tissue in situ hybridization, immunohistochemistry with multiple rounds of staining and de-staining in non-sectioned tissue, and antibody labelling throughout the intact adult mouse brain. Finally, we show that CLARITY enables fine structural analysis of clinical samples, including non-sectioned human tissue from a neuropsychiatric-disease setting, establishing a path for the transmutation of human tissue into a stable, intact and accessible form suitable for probing structural and molecular underpinnings of physiological function and disease. © 2013 Macmillan Publishers Limited. All rights reserved.},
  author   = {Kwanghun Chung and Jenelle Wallace and Sung Yon Kim and Sandhiya Kalyanasundaram and Aaron S. Andalman and Thomas J. Davidson and Julie J. Mirzabekov and Kelly A. Zalocusky and Joanna Mattis and Aleksandra K. Denisin and Sally Pak and Hannah Bernstein and Charu Ramakrishnan and Logan Grosenick and Viviana Gradinaru and Karl Deisseroth},
  doi      = {10.1038/nature12107},
  issn     = {00280836},
  issue    = {7449},
  journal  = {Nature},
  month    = {5},
  pages    = {332-337},
  pmid     = {23575631},
  title    = {Structural and molecular interrogation of intact biological systems},
  volume   = {497},
  year     = {2013}
}
@article{Jiang2023,
  abstract  = {The mammalian brain is a highly complex network that consists of millions to billions of densely-interconnected neurons. Precise dissection of neural circuits at the mesoscopic level can provide important structural information for understanding the brain. Optical approaches can achieve submicron lateral resolution and achieve “optical sectioning” by a variety of means, which has the natural advantage of allowing the observation of neural circuits at the mesoscopic level. Automated whole-brain optical imaging methods based on tissue clearing or histological sectioning surpass the limitation of optical imaging depth in biological tissues and can provide delicate structural information in a large volume of tissues. Combined with various fluorescent labeling techniques, whole-brain optical imaging methods have shown great potential in the brain-wide quantitative profiling of cells, circuits, and blood vessels. In this review, we summarize the principles and implementations of various whole-brain optical imaging methods and provide some concepts regarding their future development.},
  author    = {Tao Jiang and Hui Gong and Jing Yuan},
  doi       = {10.1007/s12264-023-01112-y},
  issn      = {19958218},
  issue     = {12},
  journal   = {Neuroscience Bulletin},
  keywords  = {Brain connectome,Micrometer resolution,Neural circuits,Neuron,Optical sectioning,Whole-brain optical imaging},
  month     = {12},
  pages     = {1840-1858},
  pmid      = {37715920},
  publisher = {Springer},
  title     = {Whole-brain Optical Imaging: A Powerful Tool for Precise Brain Mapping at the Mesoscopic Level},
  volume    = {39},
  year      = {2023}
}
@article{Gong2013,
  abstract = {Revealing neural circuit mechanisms is critical for understanding brain functions. Significant progress in dissecting neural connections has been made using optical imaging with fluorescence labels, especially in dissecting local connections. However, acquiring and tracing brain-wide, long-distance neural circuits at the neurite level remains a substantial challenge. Here, we describe a whole-brain approach to systematically obtaining continuous neuronal pathways in a fluorescent protein transgenic mouse at a one-micron voxel resolution. This goal is achieved by combining a novel resin-embedding method for maintaining fluorescence, an automated fluorescence micro-optical sectioning tomography system for long-term stable imaging, and a digital reconstruction-registration-annotation pipeline for tracing the axonal pathways in the mouse brain. With the unprecedented ability to image a whole mouse brain at a one-micron voxel resolution, the long-distance pathways were traced minutely and without interruption for the first time. With advancing labeling techniques, our method is believed to open an avenue to exploring both local and long-distance neural circuits that are related to brain functions and brain diseases down to the neurite level. © 2013 Elsevier Inc.},
  author   = {Hui Gong and Shaoqun Zeng and Cheng Yan and Xiaohua Lv and Zhongqin Yang and Tonghui Xu and Zhao Feng and Wenxiang Ding and Xiaoli Qi and Anan Li and Jingpeng Wu and Qingming Luo},
  doi      = {10.1016/j.neuroimage.2013.02.005},
  issn     = {10538119},
  journal  = {NeuroImage},
  keywords = {Brain-wide long-distance axonal projection,Fluorescence imaging,Micro-optical sectioning tomography,Mouse brain},
  month    = {7},
  pages    = {87-98},
  pmid     = {23416252},
  title    = {Continuously tracing brain-wide long-distance axonal projections in mice at a one-micron voxel resolution},
  volume   = {74},
  year     = {2013}
}
@article{Susaki2014,
  abstract  = {Systems-level identification and analysis of cellular circuits in the brain will require the development of whole-brain imaging with single-cell resolution. To this end, we performed comprehensive chemical screening to develop a whole-brain clearing and imaging method, termed CUBIC (clear, unobstructed brain imaging cocktails and computational analysis). CUBIC is a simple and efficient method involving the immersion of brain samples in chemical mixtures containing aminoalcohols, which enables rapid whole-brain imaging with single-photon excitation microscopy. CUBIC is applicable to multicolor imaging of fluorescent proteins or immunostained samples in adult brains and is scalable from a primate brain to subcellular structures. We also developed a whole-brain cell-nuclear counterstaining protocol and a computational image analysis pipeline that, together with CUBIC reagents, enable the visualization and quantification of neural activities induced by environmental stimulation. CUBIC enables time-course expression profiling of whole adult brains with single-cell resolution. © 2014 Elsevier Inc.},
  author    = {Etsuo A. Susaki and Kazuki Tainaka and Dimitri Perrin and Fumiaki Kishino and Takehiro Tawara and Tomonobu M. Watanabe and Chihiro Yokoyama and Hirotaka Onoe and Megumi Eguchi and Shun Yamaguchi and Takaya Abe and Hiroshi Kiyonari and Yoshihiro Shimizu and Atsushi Miyawaki and Hideo Yokota and Hiroki R. Ueda},
  doi       = {10.1016/j.cell.2014.03.042},
  issn      = {10974172},
  issue     = {3},
  journal   = {Cell},
  month     = {4},
  pages     = {726-739},
  pmid      = {24746791},
  publisher = {Elsevier B.V.},
  title     = {Whole-brain imaging with single-cell resolution using chemical cocktails and computational analysis},
  volume    = {157},
  year      = {2014}
}

@article{Moen2019,
  abstract  = {Recent advances in computer vision and machine learning underpin a collection of algorithms with an impressive ability to decipher the content of images. These deep learning algorithms are being applied to biological images and are transforming the analysis and interpretation of imaging data. These advances are positioned to render difficult analyses routine and to enable researchers to carry out new, previously impossible experiments. Here we review the intersection between deep learning and cellular image analysis and provide an overview of both the mathematical mechanics and the programming frameworks of deep learning that are pertinent to life scientists. We survey the field’s progress in four key applications: image classification, image segmentation, object tracking, and augmented microscopy. Last, we relay our labs’ experience with three key aspects of implementing deep learning in the laboratory: annotating training data, selecting and training a range of neural network architectures, and deploying solutions. We also highlight existing datasets and implementations for each surveyed application.},
  author    = {Erick Moen and Dylan Bannon and Takamasa Kudo and William Graf and Markus Covert and David Van Valen},
  doi       = {10.1038/s41592-019-0403-1},
  issn      = {15487105},
  issue     = {12},
  journal   = {Nature Methods},
  month     = {12},
  pages     = {1233-1246},
  pmid      = {31133758},
  publisher = {Nature Research},
  title     = {Deep learning for cellular image analysis},
  volume    = {16},
  year      = {2019}
}
@article{Lecun2015,
  abstract  = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  author    = {Yann Lecun and Yoshua Bengio and Geoffrey Hinton},
  doi       = {10.1038/nature14539},
  issn      = {14764687},
  issue     = {7553},
  journal   = {Nature},
  month     = {5},
  pages     = {436-444},
  pmid      = {26017442},
  publisher = {Nature Publishing Group},
  title     = {Deep learning},
  volume    = {521},
  year      = {2015}
}
@article{Vazdarjanova2006,
  abstract = {Active behavior, such as exploring a novel environment, induces the expression of the immediate-early gene Arc (activity-regulated cytoskeletal associated protein, or Arg 3.1) in many brain regions, including the hippocampus, neocortex, and striatum. Arc messenger ribonucleic acid and protein are localized in activated dendrites, and Arc protein is required for the maintenance of long-term potentiation and memory consolidation. Although previous evidence suggests that Arc is expressed in neurons, there is no direct demonstration that only neurons can express Arc. Furthermore, there is no characterization of the main neuronal types that express Arc. The data reported here show that behavior- or seizure-induced Arc expression in the hippocampus, primary somatosensory cortex, and dorsal striatum of rats colocalizes only with neuronal (NeuN-positive) and not with glial (GFAP-positive) cells. Furthermore, Arc was found exclusively in non-GABAergic α-CaMKII-positive hippocampal and neocortical neurons of rats that had explored a novel environment. Some GAD65/67-positive neurons in these regions were observed to express Arc, but only after a very strong stimulus (electroconvulsive seizure). In the dorsal striatum, spatial exploration induced Arc only in GASAergic and α-CaMKII-positive neurons. Combined, these results show that although a very strong stimulus (seizure) can induce Arc in a variety of neurons, behavior induces Arc in the CaMKII-positive principal neurons of the hippocampus, neocortex, and dorsal striatum. These results, coupled with recent in vitro findings of interactions between Arc and CaMKII, are consistent with the hypothesis that Arc and CaMKII act as plasticity partners to promote functional and/or structural synaptic modifications that accompany learning. © 2006 Wiley-Liss, Inc.},
  author   = {Almira Vazdarjanova and Victor Ramirez-Amaya and Nathan Insel and Thane K. Plummer and Susanna Rosi and Shoaib Chowdhury and Dalia Mikhael and Paul F. Worley and John F. Guzowski and Carol A. Barnes},
  doi      = {10.1002/cne.21003},
  issn     = {00219967},
  issue    = {3},
  journal  = {Journal of Comparative Neurology},
  keywords = {GAD,GFAP,Hippocampus,Plasticity,Primary somatosensory cortex,Striatum},
  month    = {9},
  pages    = {317-329},
  pmid     = {16871537},
  title    = {Spatial exploration induces ARC, a plasticity-related immediate-early gene, only in calcium/calmodulin-dependent protein kinase II-positive principal excitatory and inhibitory neurons of the rat forebrain},
  volume   = {498},
  year     = {2006}
}
@article{Yi2019,
  abstract  = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
  author    = {Xin Yi and Ekta Walia and Paul Babyn},
  doi       = {10.1016/j.media.2019.101552},
  issn      = {13618423},
  journal   = {Medical Image Analysis},
  keywords  = {Deep learning,Generative adversarial network,Generative model,Medical imaging,Review},
  month     = {12},
  pmid      = {31521965},
  publisher = {Elsevier B.V.},
  title     = {Generative adversarial network in medical imaging: A review},
  volume    = {58},
  year      = {2019}
}
@article{Geirhos2020,
  abstract  = {Deep learning has triggered the current rise of artificial intelligence and is the workhorse of today’s machine intelligence. Numerous success stories have rapidly spread all over science, industry and society, but its limitations have only recently come into focus. In this Perspective we seek to distil how many of deep learning’s failures can be seen as different symptoms of the same underlying problem: shortcut learning. Shortcuts are decision rules that perform well on standard benchmarks but fail to transfer to more challenging testing conditions, such as real-world scenarios. Related issues are known in comparative psychology, education and linguistics, suggesting that shortcut learning may be a common characteristic of learning systems, biological and artificial alike. Based on these observations, we develop a set of recommendations for model interpretation and benchmarking, highlighting recent advances in machine learning to improve robustness and transferability from the lab to real-world applications.},
  author    = {Robert Geirhos and Jörn Henrik Jacobsen and Claudio Michaelis and Richard Zemel and Wieland Brendel and Matthias Bethge and Felix A. Wichmann},
  doi       = {10.1038/s42256-020-00257-z},
  issn      = {25225839},
  issue     = {11},
  journal   = {Nature Machine Intelligence},
  month     = {11},
  pages     = {665-673},
  publisher = {Nature Research},
  title     = {Shortcut learning in deep neural networks},
  volume    = {2},
  year      = {2020}
}
@article{Ueda2020a,
  abstract  = {Tissue clearing and light-sheet microscopy form powerful synergies for neuroscience. In this issue of Neuron, Ueda et al. review how these technologies enable brain-wide profiling of cells and circuits for a systems-level understanding of the physiology and pathology of our nervous system.},
  author    = {Hiroki R. Ueda and Hans Ulrich Dodt and Pavel Osten and Michael N. Economo and Jayaram Chandrashekar and Philipp J. Keller},
  doi       = {10.1016/j.neuron.2020.03.004},
  issn      = {10974199},
  issue     = {3},
  journal   = {Neuron},
  month     = {5},
  pages     = {369-387},
  pmid      = {32380050},
  publisher = {Cell Press},
  title     = {Whole-Brain Profiling of Cells and Circuits in Mammals by Tissue Clearing and Light-Sheet Microscopy},
  volume    = {106},
  year      = {2020}
}
@article{Attarpour2025,
  abstract  = {Teravoxel-scale, cellular-resolution images of cleared rodent brains acquired with light-sheet fluorescence microscopy have transformed the way we study the brain. Realizing the potential of this technology requires computational pipelines that generalize across experimental protocols and map neuronal activity at the laminar and subpopulation-specific levels, beyond atlas-defined regions. Here, we present artficial intelligence-based cartography of ensembles (ACE), an end-to-end pipeline that employs three-dimensional deep learning segmentation models and advanced cluster-wise statistical algorithms, to enable unbiased mapping of local neuronal activity and connectivity. Validation against state-of-the-art segmentation and detection methods on unseen datasets demonstrated ACE’s high generalizability and performance. Applying ACE in two distinct neurobiological contexts, we discovered subregional effects missed by existing atlas-based analyses and showcase ACE’s ability to reveal localized or laminar neuronal activity brain-wide. Our open-source pipeline enables whole-brain mapping of neuronal ensembles at a high level of precision across a wide range of neuroscientific applications.},
  author    = {Ahmadreza Attarpour and Jonas Osmann and Anthony Rinaldi and Tianbo Qi and Neeraj Lal and Shruti Patel and Matthew Rozak and Fengqing Yu and Newton Cho and Jordan Squair and Jo Anne McLaurin and Misha Raffiee and Karl Deisseroth and Gregoire Courtine and Li Ye and Bojana Stefanovic and Maged Goubran},
  doi       = {10.1038/s41592-024-02583-1},
  issn      = {15487105},
  issue     = {3},
  journal   = {Nature Methods},
  month     = {3},
  pages     = {600-611},
  pmid      = {39870865},
  publisher = {Nature Research},
  title     = {A deep learning pipeline for three-dimensional brain-wide mapping of local neuronal ensembles in teravoxel light-sheet microscopy},
  volume    = {22},
  year      = {2025}
}
@article{Wang2021,
  abstract  = {Automatic medical image segmentation plays a critical role in scientific research and medical care. Existing high-performance deep learning methods typically rely on large training datasets with high-quality manual annotations, which are difficult to obtain in many clinical applications. Here, we introduce Annotation-effIcient Deep lEarning (AIDE), an open-source framework to handle imperfect training datasets. Methodological analyses and empirical evaluations are conducted, and we demonstrate that AIDE surpasses conventional fully-supervised models by presenting better performance on open datasets possessing scarce or noisy annotations. We further test AIDE in a real-life case study for breast tumor segmentation. Three datasets containing 11,852 breast images from three medical centers are employed, and AIDE, utilizing 10\% training annotations, consistently produces segmentation maps comparable to those generated by fully-supervised counterparts or provided by independent radiologists. The 10-fold enhanced efficiency in utilizing expert labels has the potential to promote a wide range of biomedical applications.},
  author    = {Shanshan Wang and Cheng Li and Rongpin Wang and Zaiyi Liu and Meiyun Wang and Hongna Tan and Yaping Wu and Xinfeng Liu and Hui Sun and Rui Yang and Xin Liu and Jie Chen and Huihui Zhou and Ismail Ben Ayed and Hairong Zheng},
  doi       = {10.1038/s41467-021-26216-9},
  issn      = {20411723},
  issue     = {1},
  journal   = {Nature Communications},
  month     = {12},
  pmid      = {34625565},
  publisher = {Nature Research},
  title     = {Annotation-efficient deep learning for automatic medical image segmentation},
  volume    = {12},
  year      = {2021}
}
@article{Ueda2020b,
  abstract  = {State-of-the-art tissue-clearing methods provide subcellular-level optical access to intact tissues from individual organs and even to some entire mammals. When combined with light-sheet microscopy and automated approaches to image analysis, existing tissue-clearing methods can speed up and may reduce the cost of conventional histology by several orders of magnitude. In addition, tissue-clearing chemistry allows whole-organ antibody labelling, which can be applied even to thick human tissues. By combining the most powerful labelling, clearing, imaging and data-analysis tools, scientists are extracting structural and functional cellular and subcellular information on complex mammalian bodies and large human specimens at an accelerated pace. The rapid generation of terabyte-scale imaging data furthermore creates a high demand for efficient computational approaches that tackle challenges in large-scale data analysis and management. In this Review, we discuss how tissue-clearing methods could provide an unbiased, system-level view of mammalian bodies and human specimens and discuss future opportunities for the use of these methods in human neuroscience.},
  author    = {Hiroki R. Ueda and Ali Ertürk and Kwanghun Chung and Viviana Gradinaru and Alain Chédotal and Pavel Tomancak and Philipp J. Keller},
  doi       = {10.1038/s41583-019-0250-1},
  issn      = {14710048},
  issue     = {2},
  journal   = {Nature Reviews Neuroscience},
  month     = {2},
  pages     = {61-79},
  pmid      = {31896771},
  publisher = {Nature Research},
  title     = {Tissue clearing and its applications in neuroscience},
  volume    = {21},
  year      = {2020}
}
@article{Tajbakhsh2020,
  abstract  = {The medical imaging literature has witnessed remarkable progress in high-performing segmentation models based on convolutional neural networks. Despite the new performance highs, the recent advanced segmentation models still require large, representative, and high quality annotated datasets. However, rarely do we have a perfect training dataset, particularly in the field of medical imaging, where data and annotations are both expensive to acquire. Recently, a large body of research has studied the problem of medical image segmentation with imperfect datasets, tackling two major dataset limitations: scarce annotations where only limited annotated data is available for training, and weak annotations where the training data has only sparse annotations, noisy annotations, or image-level annotations. In this article, we provide a detailed review of the solutions above, summarizing both the technical novelties and empirical results. We further compare the benefits and requirements of the surveyed methodologies and provide our recommended solutions. We hope this survey article increases the community awareness of the techniques that are available to handle imperfect medical image segmentation datasets.},
  author    = {Nima Tajbakhsh and Laura Jeyaseelan and Qian Li and Jeffrey N. Chiang and Zhihao Wu and Xiaowei Ding},
  doi       = {10.1016/j.media.2020.101693},
  issn      = {13618423},
  journal   = {Medical Image Analysis},
  keywords  = {And weak annotations,Imperfect dataset,Medical image segmentation,Noisy annotations,Scarce annotations,Sparse annotations,Unreliable annotations},
  month     = {7},
  pmid      = {32289663},
  publisher = {Elsevier B.V.},
  title     = {Embracing imperfect datasets: A review of deep learning solutions for medical image segmentation},
  volume    = {63},
  year      = {2020}
}
@article{Cooper2010,
  abstract  = {People exert large amounts of problem-solving effort playing computer games. Simple image-and text-recognition tasks have been successfully ĝ€̃ crowd-sourced' through games, but it is not clear if more complex scientific problems can be solved with human-directed computing. Protein structure prediction is one such problem: locating the biologically relevant native conformation of a protein is a formidable computational challenge given the very large size of the search space. Here we describe Foldit, a multiplayer online game that engages non-scientists in solving hard prediction problems. Foldit players interact with protein structures using direct manipulation tools and user-friendly versions of algorithms from the Rosetta structure prediction methodology, while they compete and collaborate to optimize the computed energy. We show that top-ranked Foldit players excel at solving challenging structure refinement problems in which substantial backbone rearrangements are necessary to achieve the burial of hydrophobic residues. Players working collaboratively develop a rich assortment of new strategies and algorithms; unlike computational approaches, they explore not only the conformational space but also the space of possible search strategies. The integration of human visual problem-solving and strategy development capabilities with traditional computational algorithms through interactive multiplayer games is a powerful new approach to solving computationally-limited scientific problems. © 2010 Macmillan Publishers Limited. All rights reserved.},
  author    = {Seth Cooper and Firas Khatib and Adrien Treuille and Janos Barbero and Jeehyung Lee and Michael Beenen and Andrew Leaver-Fay and David Baker and Zoran Popović and Foldit Players},
  doi       = {10.1038/nature09304},
  issn      = {14764687},
  issue     = {7307},
  journal   = {Nature},
  month     = {8},
  pages     = {756-760},
  pmid      = {20686574},
  publisher = {Nature Publishing Group},
  title     = {Predicting protein structures with a multiplayer online game},
  volume    = {466},
  year      = {2010}
}
@article{Gouty-Colomer2016,
  abstract  = {Memories are encoded within sparsely distributed neuronal ensembles. However, the defining cellular properties of neurons within a memory trace remain incompletely understood. Using a fluorescence-based Arc reporter, we were able to visually identify the distinct subset of lateral amygdala (LA) neurons activated during auditory fear conditioning. We found that Arc-expressing neurons have enhanced intrinsic excitability and are preferentially recruited into newly encoded memory traces. Furthermore, synaptic potentiation of thalamic inputs to the LA during fear conditioning is learning-specific, postsynaptically mediated and highly localized to Arc-expressing neurons. Taken together, our findings validate the immediate-early gene Arc as a molecular marker for the LA neuronal ensemble recruited during fear learning. Moreover, these results establish a model of fear memory formation in which intrinsic excitability determines neuronal selection, whereas learning-related encoding is governed by synaptic plasticity.},
  author    = {L. A. Gouty-Colomer and B. Hosseini and I. M. Marcelo and J. Schreiber and D. E. Slump and S. Yamaguchi and A. R. Houweling and D. Jaarsma and Y. Elgersma and S. A. Kushner},
  doi       = {10.1038/mp.2015.18},
  issn      = {14765578},
  issue     = {3},
  journal   = {Molecular Psychiatry},
  month     = {3},
  pages     = {364-375},
  pmid      = {25802982},
  publisher = {Nature Publishing Group},
  title     = {Arc expression identifies the lateral amygdala fear memory trace},
  volume    = {21},
  year      = {2016}
}
@article{Wang2020,
  abstract  = {The Allen Mouse Brain CCF is an openly accessible, cellular level resolution 3D reference atlas for analysis, visualization, and integration of multimodal and multiscale datasets.},
  author    = {Quanxin Wang and Song Lin Ding and Yang Li and Josh Royall and David Feng and Phil Lesnar and Nile Graddis and Maitham Naeemi and Benjamin Facer and Anh Ho and Tim Dolbeare and Brandon Blanchard and Nick Dee and Wayne Wakeman and Karla E. Hirokawa and Aaron Szafer and Susan M. Sunkin and Seung Wook Oh and Amy Bernard and John W. Phillips and Michael Hawrylycz and Christof Koch and Hongkui Zeng and Julie A. Harris and Lydia Ng},
  doi       = {10.1016/j.cell.2020.04.007},
  issn      = {10974172},
  issue     = {4},
  journal   = {Cell},
  keywords  = {3D brain atlas,CCFv3,average mouse brain,brain anatomy,brain parcellation,common coordinate framework,fiber tracts,mouse cortex,reference atlas,transgenic mice},
  month     = {5},
  pages     = {936-953.e20},
  pmid      = {32386544},
  publisher = {Cell Press},
  title     = {The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas},
  volume    = {181},
  year      = {2020}
}
@article{Chiaruttini2025,
  abstract  = {Unbiased characterization of whole-brain cytoarchitecture is crucial for understanding brain function, requiring precise mapping of 2D histological sections onto 3D brain atlases. We introduce two software tools to facilitate this process: Aligning Big Brains and Atlases (ABBA), designed to streamline the precise and efficient registration of 2D sections to 3D reference atlases, and BraiAn, an integrated suite for multi-marker automated segmentation, whole-brain statistical analysis, and data visualization. Combining these tools, we conducted a comprehensive comparative study of the whole-brain expression of three widely used immediate-early genes (IEGs)—cFos, Arc, and NPAS4—across three memory-related behavioral conditions. Our findings reveal significant differences in their distribution and induction patterns, suggesting that these IEGs offer complementary, rather than equivalent, information about neural activity across brain regions and activity states.},
  author    = {Nicolas Chiaruttini and Carlo Castoldi and Linda Maria Requie and Carmen Camarena-Delgado and Beatrice Dal Bianco and Johannes Gräff and Arne Seitz and Bianca A. Silva},
  doi       = {10.1016/j.celrep.2025.115876},
  issn      = {22111247},
  issue     = {7},
  journal   = {Cell Reports},
  keywords  = {ABBA,Arc,BraiAn,CP: Neuroscience,NPAS4,atlas registration,cFos,contextual fear conditioning,engram,immediate-early genes,whole-brain mapping},
  month     = {7},
  pmid      = {40553651},
  publisher = {Elsevier B.V.},
  title     = {ABBA+BraiAn, an integrated suite for whole-brain mapping, reveals brain-wide differences in immediate-early genes induction upon learning},
  volume    = {44},
  year      = {2025}
}
@article{Amgad2019,
  abstract  = {While deep-learning algorithms have demonstrated outstanding performance in semantic image segmentation tasks, large annotation datasets are needed to create accurate models. Annotation of histology images is challenging due to the effort and experience required to carefully delineate tissue structures, and difficulties related to sharing and markup of whole-slide images. Results: We recruited 25 participants, ranging in experience from senior pathologists to medical students, to delineate tissue regions in 151 breast cancer slides using the Digital Slide Archive. Inter-participant discordance was systematically evaluated, revealing low discordance for tumor and stroma, and higher discordance for more subjectively defined or rare tissue classes. Feedback provided by senior participants enabled the generation and curation of 20 000+ annotated tissue regions. Fully convolutional networks trained using these annotations were highly accurate (mean AUC=0.945), and the scale of annotation data provided notable improvements in image classification accuracy. Availability and Implementation: Dataset is freely available at: https://goo.gl/cNM4EL. Supplementary information: Supplementary data are available at Bioinformatics online.},
  author    = {Mohamed Amgad and Habiba Elfandy and Hagar Hussein and Lamees A. Atteya and Mai A.T. Elsebaie and Lamia S. Abo Elnasr and Rokia A. Sakr and Hazem S.E. Salem and Ahmed F. Ismail and Anas M. Saad and Joumana Ahmed and Maha A.T. Elsebaie and Mustafijur Rahman and Inas A. Ruhban and Nada M. Elgazar and Yahya Alagha and Mohamed H. Osman and Ahmed M. Alhusseiny and Mariam M. Khalaf and Abo Alela F. Younes and Ali Abdulkarim and Duaa M. Younes and Ahmed M. Gadallah and Ahmad M. Elkashash and Salma Y. Fala and Basma M. Zaki and Jonathan Beezley and Deepak R. Chittajallu and David Manthey and David A. Gutman and Lee A.D. Cooper and Robert Murphy},
  doi       = {10.1093/bioinformatics/btz083},
  issn      = {14602059},
  issue     = {18},
  journal   = {Bioinformatics},
  month     = {9},
  pages     = {3461-3467},
  pmid      = {30726865},
  publisher = {Oxford University Press},
  title     = {Structured crowdsourcing enables convolutional segmentation of histology images},
  volume    = {35},
  year      = {2019}
}
@article{Litjens2017,
  abstract  = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
  author    = {Geert Litjens and Thijs Kooi and Babak Ehteshami Bejnordi and Arnaud Arindra Adiyoso Setio and Francesco Ciompi and Mohsen Ghafoorian and Jeroen A.W.M. van der Laak and Bram van Ginneken and Clara I. Sánchez},
  doi       = {10.1016/j.media.2017.07.005},
  issn      = {13618423},
  journal   = {Medical Image Analysis},
  keywords  = {Convolutional neural networks,Deep learning,Medical imaging,Survey},
  month     = {12},
  pages     = {60-88},
  pmid      = {28778026},
  publisher = {Elsevier B.V.},
  title     = {A survey on deep learning in medical image analysis},
  volume    = {42},
  year      = {2017}
}

@article{DBLP:journals/corr/abs-1803-01229,
  author     = {Maayan Frid{-}Adar and
                Idit Diamant and
                Eyal Klang and
                Michal Amitai and
                Jacob Goldberger and
                Hayit Greenspan},
  title      = {GAN-based Synthetic Medical Image Augmentation for increased {CNN}
                Performance in Liver Lesion Classification},
  journal    = {CoRR},
  volume     = {abs/1803.01229},
  year       = {2018},
  url        = {http://arxiv.org/abs/1803.01229},
  eprinttype = {arXiv},
  eprint     = {1803.01229},
  timestamp  = {Mon, 13 Aug 2018 16:48:12 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1803-01229.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{ShortenK19,
  title     = {A survey on Image Data Augmentation for Deep Learning},
  author    = {Connor Shorten and Taghi M. Khoshgoftaar},
  year      = {2019},
  doi       = {10.1186/s40537-019-0197-0},
  url       = {https://doi.org/10.1186/s40537-019-0197-0},
  researchr = {https://researchr.org/publication/ShortenK19},
  cites     = {0},
  citedby   = {0},
  journal   = {J. Big Data},
  volume    = {6},
  pages     = {60}
}

@article{Avants2011,
  abstract = {The United States National Institutes of Health (NIH) commit significant support to open-source data and software resources in order to foment reproducibility in the biomedical imaging sciences. Here, we report and evaluate a recent product of this commitment: Advanced Neuroimaging Tools (ANTs), which is approaching its 2.0 release. The ANTs open source software library consists of a suite of state-of-the-art image registration, segmentation and template building tools for quantitative morphometric analysis. In this work, we use ANTs to quantify, for the first time, the impact of similarity metrics on the affine and deformable components of a template-based normalization study. We detail the ANTs implementation of three similarity metrics: squared intensity difference, a new and faster cross-correlation, and voxel-wise mutual information. We then use two-fold cross-validation to compare their performance on openly available, manually labeled, T1-weighted MRI brain image data of 40 subjects (UCLA's LPBA40 dataset). We report evaluation results on cortical and whole brain labels for both the affine and deformable components of the registration. Results indicate that the best ANTs methods are competitive with existing brain extraction results (Jaccard = 0.958) and cortical labeling approaches. Mutual information affine mapping combined with cross-correlation diffeomorphic mapping gave the best cortical labeling results (Jaccard = 0.669. ±. 0.022). Furthermore, our two-fold cross-validation allows us to quantify the similarity of templates derived from different subgroups. Our open code, data and evaluation scripts set performance benchmark parameters for this state-of-the-art toolkit. This is the first study to use a consistent transformation framework to provide a reproducible evaluation of the isolated effect of the similarity metric on optimal template construction and brain labeling. © 2010 Elsevier Inc.},
  author   = {Brian B. Avants and Nicholas J. Tustison and Gang Song and Philip A. Cook and Arno Klein and James C. Gee},
  doi      = {10.1016/j.neuroimage.2010.09.025},
  issn     = {10538119},
  issue    = {3},
  journal  = {NeuroImage},
  month    = {2},
  pages    = {2033-2044},
  pmid     = {20851191},
  title    = {A reproducible evaluation of ANTs similarity metric performance in brain image registration},
  volume   = {54},
  year     = {2011}
}
@article{Jakubik2024,
  abstract  = {Data-centric artificial intelligence (data-centric AI) represents an emerging paradigm that emphasizes the importance of enhancing data systematically and at scale to build effective and efficient AI-based systems. The novel paradigm complements recent model-centric AI, which focuses on improving the performance of AI-based systems based on changes in the model using a fixed set of data. The objective of this article is to introduce practitioners and researchers from the field of Business and Information Systems Engineering (BISE) to data-centric AI. The paper defines relevant terms, provides key characteristics to contrast the paradigm of data-centric AI with the model-centric one, and introduces a framework to illustrate the different dimensions of data-centric AI. In addition, an overview of available tools for data-centric AI is presented and this novel paradigm is differenciated from related concepts. Finally, the paper discusses the longer-term implications of data-centric AI for the BISE community.},
  author    = {Johannes Jakubik and Michael Vössing and Niklas Kühl and Jannis Walk and Gerhard Satzger},
  doi       = {10.1007/s12599-024-00857-8},
  issn      = {18670202},
  issue     = {4},
  journal   = {Business and Information Systems Engineering},
  keywords  = {Data quality,Data work,Data-centric artificial intelligence},
  month     = {8},
  pages     = {507-515},
  publisher = {Springer Gabler},
  title     = {Data-Centric Artificial Intelligence},
  volume    = {66},
  year      = {2024}
}
@article{Ragan2012,
  abstract  = {Here we describe an automated method, named serial two-photon (STP) tomography, that achieves high-throughput fluorescence imaging of mouse brains by integrating two-photon microscopy and tissue sectioning. STP tomography generates high-resolution datasets that are free of distortions and can be readily warped in three dimensions, for example, for comparing multiple anatomical tracings. This method opens the door to routine systematic studies of neuroanatomy in mouse models of human brain disorders. © 2012 Nature America, Inc. All rights reserved.},
  author    = {Timothy Ragan and Lolahon R. Kadiri and Kannan Umadevi Venkataraju and Karsten Bahlmann and Jason Sutin and Julian Taranda and Ignacio Arganda-Carreras and Yongsoo Kim and H. Sebastian Seung and Pavel Osten},
  doi       = {10.1038/nmeth.1854},
  issn      = {15487105},
  issue     = {3},
  journal   = {Nature Methods},
  pages     = {255-258},
  pmid      = {22245809},
  publisher = {Nature Publishing Group},
  title     = {Serial two-photon tomography for automated ex vivo mouse brain imaging},
  volume    = {9},
  year      = {2012}
}
@article{Berg2019,
  abstract  = {We present ilastik, an easy-to-use interactive tool that brings machine-learning-based (bio)image analysis to end users without substantial computational expertise. It contains pre-defined workflows for image segmentation, object classification, counting and tracking. Users adapt the workflows to the problem at hand by interactively providing sparse training annotations for a nonlinear classifier. ilastik can process data in up to five dimensions (3D, time and number of channels). Its computational back end runs operations on-demand wherever possible, allowing for interactive prediction on data larger than RAM. Once the classifiers are trained, ilastik workflows can be applied to new data from the command line without further user interaction. We describe all ilastik workflows in detail, including three case studies and a discussion on the expected performance.},
  author    = {Stuart Berg and Dominik Kutra and Thorben Kroeger and Christoph N. Straehle and Bernhard X. Kausler and Carsten Haubold and Martin Schiegg and Janez Ales and Thorsten Beier and Markus Rudy and Kemal Eren and Jaime I. Cervantes and Buote Xu and Fynn Beuttenmueller and Adrian Wolny and Chong Zhang and Ullrich Koethe and Fred A. Hamprecht and Anna Kreshuk},
  doi       = {10.1038/s41592-019-0582-9},
  issn      = {15487105},
  issue     = {12},
  journal   = {Nature Methods},
  month     = {12},
  pages     = {1226-1232},
  pmid      = {31570887},
  publisher = {Nature Research},
  title     = {ilastik: interactive machine learning for (bio)image analysis},
  volume    = {16},
  year      = {2019}
}
@article{Mitry2016,
  author  = {Danny Mitry and Kris Zutis and Baljean Dhillon and Tunde Peto and Shabina Hayat and Kay-Tee Khaw and James E. Morgan and Wendy Moncur and Emanuele Trucco and Paul J. Foster},
  doi     = {10.1167/tvst.5.5.6},
  issn    = {2164-2591},
  issue   = {5},
  journal = {Translational Vision Science \& Technology},
  month   = {9},
  pages   = {6},
  title   = {The Accuracy and Reliability of Crowdsource Annotations of Digital Retinal Images},
  volume  = {5},
  url     = {http://tvst.arvojournals.org/article.aspx?doi=10.1167/tvst.5.5.6},
  year    = {2016}
}
@article{Bonney2009,
  abstract = {Citizen science enlists the public in collecting large quantities of data across an array of habitats and locations over long spans of time. Citizen science projects have been remarkably successful in advancing scientific knowledge, and contributions from citizen scientists now provide a vast quantity of data about species occurrence and distribution around the world. Most citizen science projects also strive to help participants learn about the organisms they are observing and to experience the process by which scientific investigations are conducted. Developing and implementing public data-collection projects that yield both scientific and educational outcomes requires significant effort. This article describes the model for building and operating citizen science projects that has evolved at the Cornell Lab of Ornithology over the past two decades. We hope that our model will inform the fields of biodiversity monitoring, biological research, and science education while providing a window into the culture of citizen science. © 2009 by American Institute of Biological Sciences. All rights reserved.},
  author   = {Rick Bonney and Caren B. Cooper and Janis Dickinson and Steve Kelling and Tina Phillips and Kenneth V. Rosenberg and Jennifer Shirk},
  doi      = {10.1525/bio.2009.59.11.9},
  issn     = {00063568},
  issue    = {11},
  journal  = {BioScience},
  keywords = {Citizen science,Public participation in research,Public scientific literacy},
  month    = {12},
  pages    = {977-984},
  title    = {Citizen science: A developing tool for expanding science knowledge and scientific literacy},
  volume   = {59},
  year     = {2009}
}
@inproceedings{Ronneberger2015,
  abstract  = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
  author    = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  doi       = {10.1007/978-3-319-24574-4_28},
  isbn      = {9783319245737},
  issn      = {16113349},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  pages     = {234-241},
  publisher = {Springer Verlag},
  title     = {U-net: Convolutional networks for biomedical image segmentation},
  volume    = {9351},
  year      = {2015}
}
@article{Lintott2008,
  abstract  = {In order to understand the formation and subsequent evolution of galaxies one must first distinguish between the two main morphological classes of massive systems: spirals and early-type systems. This paper introduces a project, Galaxy Zoo, which provides visual morphological classifications for nearly one million galaxies, extracted from the Sloan Digital Sky Survey (SDSS). This achievement was made possible by inviting the general public to visually inspect and classify these galaxies via the internet. The project has obtained more than 4 × 107 individual classifications made by ∼10 5 participants. We discuss the motivation and strategy for this project, and detail how the classifications were performed and processed. We find that Galaxy Zoo results are consistent with those for subsets of SDSS galaxies classified by professional astronomers, thus demonstrating that our data provide a robust morphological catalogue. Obtaining morphologies by direct visual inspection avoids introducing biases associated with proxies for morphology such as colour, concentration or structural parameters. In addition, this catalogue can be used to directly compare SDSS morphologies with older data sets. The colour-magnitude diagrams for each morphological class are shown, and we illustrate how these distributions differ from those inferred using colour alone as a proxy for morphology. © 2008 RAS.},
  author    = {Chris J. Lintott and Kevin Schawinski and Anže Slosar and Kate Land and Steven Bamford and Daniel Thomas and M. Jordan Raddick and Robert C. Nichol and Alex Szalay and Dan Andreescu and Phil Murray and Jan Vandenberg},
  doi       = {10.1111/j.1365-2966.2008.13689.x},
  issn      = {13652966},
  issue     = {3},
  journal   = {Monthly Notices of the Royal Astronomical Society},
  keywords  = {Galaxies: elliptical and lenticular, cD,Galaxies: general,Galaxies: spiral,Methods: data analysis},
  pages     = {1179-1189},
  publisher = {Oxford University Press},
  title     = {Galaxy Zoo: Morphologies derived from visual inspection of galaxies from the Sloan Digital Sky Survey},
  volume    = {389},
  year      = {2008}
}
@article{Campello2015,
  abstract  = {An integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan's classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of "outlierness" can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a "flat"(i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.},
  author    = {Ricardo J.G.B. Campello and Davoud Moulavi and Arthur Zimek and Jörg Sander},
  doi       = {10.1145/2733381},
  issn      = {1556472X},
  issue     = {1},
  journal   = {ACM Transactions on Knowledge Discovery from Data},
  keywords  = {Algorithms,Clustering,Data mining,Data visualization,Density-based clustering,Global/local outliers,H.2.8 [database mamagement]: Database applications - Data mining,H.3.3 [information storage and retrieval]: Information search and retrieval - Clustering,Hierarchical and nonhierarchical clustering,I.5.3 [pattern recognition]: Clustering - Algorithms,Outlier detection,Unsupervised and semisupervised clustering},
  month     = {7},
  publisher = {Association for Computing Machinery},
  title     = {Hierarchical density estimates for data clustering, visualization, and outlier detection},
  volume    = {10},
  year      = {2015}
}
@article{Lucena2019,
  abstract  = {Manual annotation is considered to be the “gold standard” in medical imaging analysis. However, medical imaging datasets that include expert manual segmentation are scarce as this step is time-consuming, and therefore expensive. Moreover, single-rater manual annotation is most often used in data-driven approaches making the network biased to only that single expert. In this work, we propose a CNN for brain extraction in magnetic resonance (MR) imaging, that is fully trained with what we refer to as “silver standard” masks. Therefore, eliminating the cost associated with manual annotation. Silver standard masks are generated by forming the consensus from a set of eight, public, non-deep-learning-based brain extraction methods using the Simultaneous Truth and Performance Level Estimation (STAPLE) algorithm. Our method consists of (1) developing a dataset with “silver standard” masks as input, and implementing (2) a tri-planar method using parallel 2D U-Net-based convolutional neural networks (CNNs) (referred to as CONSNet). This term refers to our integrated approach, i.e., training with silver standard masks and using a 2D U-Net-based architecture. We conducted our analysis using three public datasets: the Calgary-Campinas-359 (CC-359), the LONI Probabilistic Brain Atlas (LPBA40), and the Open Access Series of Imaging Studies (OASIS). Five performance metrics were used in our experiments: Dice coefficient, sensitivity, specificity, Hausdorff distance, and symmetric surface-to-surface mean distance. Our results showed that we outperformed (i.e., larger Dice coefficients) the current state-of-the-art skull-stripping methods without using gold standard annotation for the CNNs training stage. CONSNet is the first deep learning approach that is fully trained using silver standard data and is, thus, more generalizable. Using these masks, we eliminate the cost of manual annotation, decreased inter-/intra-rater variability, and avoided CNN segmentation overfitting towards one specific manual annotation guideline that can occur when gold standard masks are used. Moreover, once trained, our method takes few seconds to process a typical brain image volume using modern a high-end GPU. In contrast, many of the other competitive methods have processing times in the order of minutes.},
  author    = {Oeslle Lucena and Roberto Souza and Letícia Rittner and Richard Frayne and Roberto Lotufo},
  doi       = {10.1016/j.artmed.2019.06.008},
  issn      = {18732860},
  journal   = {Artificial Intelligence in Medicine},
  keywords  = {Convolutional neural network (CNN),Data augmentation,Silver standard masks,Skull-stripping},
  month     = {7},
  pages     = {48-58},
  pmid      = {31521252},
  publisher = {Elsevier B.V.},
  title     = {Convolutional neural networks for skull-stripping in brain MR imaging using silver standard masks},
  volume    = {98},
  year      = {2019}
}
@article{Osten2013,
  abstract = {The beginning of the 21st century has seen a renaissance in light microscopy and anatomical tract tracing that together are rapidly advancing our understanding of the form and function of neuronal circuits. The introduction of instruments for automated imaging of whole mouse brains, new cell type-specific and trans-synaptic tracers, and computational methods for handling the whole-brain data sets has opened the door to neuroanatomical studies at an unprecedented scale. We present an overview of the present state and future opportunities in charting long-range and local connectivity in the entire mouse brain and in linking brain circuits to function. © 2013 Nature America, Inc. All rights reserved.},
  author   = {Pavel Osten and Troy W. Margrie},
  doi      = {10.1038/nmeth.2477},
  issn     = {15487091},
  issue    = {6},
  journal  = {Nature Methods},
  month    = {4},
  pages    = {515-523},
  pmid     = {23722211},
  title    = {Mapping brain circuitry with a light microscope},
  volume   = {10},
  year     = {2013}
}
@inproceedings{Simpson2014,
  abstract  = {This paper introduces the Zooniverse citizen science project and software framework, outlining its structure from an ob- servatory perspective: both as an observable web-based sys- Tem in itself, and as an example of a platform iteratively developed according to real-world deployment and used at scale. We include details of the technical architecture of Zo- oniverse, including the mechanisms for data gathering across the Zooniverse operation, access, and analysis. We consider the lessons that can be drawn from the experience of design- ing and running Zooniverse, and how this might inform de- velopment of other web observatories.},
  author    = {Robert Simpson and Kevin R. Page and David De Roure},
  doi       = {10.1145/2567948.2579215},
  isbn      = {9781450327459},
  booktitle = {WWW 2014 Companion - Proceedings of the 23rd International Conference on World Wide Web},
  keywords  = {Citizen science,Crowdsourcing,Web observatories},
  month     = {4},
  pages     = {1049-1054},
  publisher = {Association for Computing Machinery, Inc},
  title     = {Zooniverse: Observing the world's largest citizen science platform},
  year      = {2014}
}
@article{Zech2018,
  abstract  = {Background: There is interest in using convolutional neural networks (CNNs) to analyze medical imaging to provide computer-aided diagnosis (CAD). Recent work has suggested that image classification CNNs may not generalize to new data as well as previously believed. We assessed how well CNNs generalized across three hospital systems for a simulated pneumonia screening task. Methods and findings: A cross-sectional design with multiple model training cohorts was used to evaluate model generalizability to external sites using split-sample validation. A total of 158,323 chest radiographs were drawn from three institutions: National Institutes of Health Clinical Center (NIH; 112,120 from 30,805 patients), Mount Sinai Hospital (MSH; 42,396 from 12,904 patients), and Indiana University Network for Patient Care (IU; 3,807 from 3,683 patients). These patient populations had an age mean (SD) of 46.9 years (16.6), 63.2 years (16.5), and 49.6 years (17) with a female percentage of 43.5\%, 44.8\%, and 57.3\%, respectively. We assessed individual models using the area under the receiver operating characteristic curve (AUC) for radiographic findings consistent with pneumonia and compared performance on different test sets with DeLong’s test. The prevalence of pneumonia was high enough at MSH (34.2\%) relative to NIH and IU (1.2\% and 1.0\%) that merely sorting by hospital system achieved an AUC of 0.861 (95\% CI 0.855–0.866) on the joint MSH–NIH dataset. Models trained on data from either NIH or MSH had equivalent performance on IU (P values 0.580 and 0.273, respectively) and inferior performance on data from each other relative to an internal test set (i.e., new data from within the hospital system used for training data; P values both <0.001). The highest internal performance was achieved by combining training and test data from MSH and NIH (AUC 0.931, 95\% CI 0.927–0.936), but this model demonstrated significantly lower external performance at IU (AUC 0.815, 95\% CI 0.745–0.885, P = 0.001). To test the effect of pooling data from sites with disparate pneumonia prevalence, we used stratified subsampling to generate MSH–NIH cohorts that only differed in disease prevalence between training data sites. When both training data sites had the same pneumonia prevalence, the model performed consistently on external IU data (P = 0.88). When a 10-fold difference in pneumonia rate was introduced between sites, internal test performance improved compared to the balanced model (10× MSH risk P < 0.001; 10× NIH P = 0.002), but this outperformance failed to generalize to IU (MSH 10× P < 0.001; NIH 10× P = 0.027). CNNs were able to directly detect hospital system of a radiograph for 99.95\% NIH (22,050/22,062) and 99.98\% MSH (8,386/8,388) radiographs. The primary limitation of our approach and the available public data is that we cannot fully assess what other factors might be contributing to hospital system–specific biases. Conclusion: Pneumonia-screening CNNs achieved better internal than external performance in 3 out of 5 natural comparisons. When models were trained on pooled data from sites with different pneumonia prevalence, they performed better on new pooled data from these sites but not on external data. CNNs robustly identified hospital system and department within a hospital, which can have large differences in disease burden and may confound predictions.},
  author    = {John R. Zech and Marcus A. Badgeley and Manway Liu and Anthony B. Costa and Joseph J. Titano and Eric Karl Oermann},
  doi       = {10.1371/journal.pmed.1002683},
  issn      = {15491676},
  issue     = {11},
  journal   = {PLoS Medicine},
  month     = {11},
  pmid      = {30399157},
  publisher = {Public Library of Science},
  title     = {Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study},
  volume    = {15},
  year      = {2018}
}
@article{Warfield2004,
  abstract = {Characterizing the performance of image segmentation approaches has been a persistent challenge. Performance analysis is important since segmentation algorithms often have limited accuracy and precision. Interactive drawing of the desired segmentation by human raters has often been the only acceptable approach, and yet suffers from intra-rater and inter-rater variability. Automated algorithms have been sought in order to remove the variability introduced by raters, but such algorithms must be assessed to ensure they are suitable for the task. The performance of raters (human or algorithmic) generating segmentations of medical images has been difficult to quantify because of the difficulty of obtaining or estimating a known true segmentation for clinical data. Although physical and digital phantoms can be constructed for which ground truth is known or readily estimated, such phantoms do not fully reflect clinical images due to the difficulty of constructing phantoms which reproduce the full range of imaging characteristics and normal and pathological anatomical variability observed in clinical data. Comparison to a collection of segmentations by raters is an attractive alternative since it can be carried out directly on the relevant clinical imaging data. However, the most appropriate measure or set of measures with which to compare such segmentations has not been clarified and several measures are used in practice. We present here an expectation-maximization algorithm for simultaneous truth and performance level estimation (STAPLE). The algorithm considers a collection of segmentations and computes a probabilistic estimate of the true segmentation and a measure of the performance level represented by each segmentation. The source of each segmentation in the collection may be an appropriately trained human rater or raters, or may be an automated segmentation algorithm. The probabilistic estimate of the true segmentation is formed by estimating an optimal combination of the segmentations, weighting each segmentation depending upon the estimated performance level, and incorporating a prior model for the spatial distribution of structures being segmented as well as spatial homogeneity constraints. STAPLE is straightforward to apply to clinical imaging data, it readily enables assessment of the performance of an automated image segmentation algorithm, and enables direct comparison of human rater and algorithm performance.},
  author   = {Simon K. Warfield and Kelly H. Zou and William M. Wells},
  doi      = {10.1109/TMI.2004.828354},
  issn     = {02780062},
  issue    = {7},
  journal  = {IEEE Transactions on Medical Imaging},
  keywords = {Accuracy,Classifier fusion,Expectation-maximization,Gold standard,Ground truth,Markov random field,Precision,STAPLE,Segmentation,Sensitivity,Specificity,Validation},
  month    = {7},
  pages    = {903-921},
  pmid     = {15250643},
  title    = {Simultaneous truth and performance level estimation (STAPLE): An algorithm for the validation of image segmentation},
  volume   = {23},
  year     = {2004}
}
@article{Shu2020,
  abstract  = {Motivation: For the diagnosis of cancer, manually counting nuclei on massive histopathological images is tedious and the counting results might vary due to the subjective nature of the operation. Results: This paper presents a new segmentation and counting method for nuclei, which can automatically provide nucleus counting results. This method segments nuclei with detected nuclei seed markers through a modified simple one-pass superpixel segmentation method. Rather than using a single pixel as a seed, we created a superseed for each nucleus to involve more information for improved segmentation results. Nucleus pixels are extracted by a newly proposed fusing method to reduce stain variations and preserve nucleus contour information. By evaluating segmentation results, the proposed method was compared to five existing methods on a dataset with 52 immunohistochemically (IHC) stained images. Our proposed method produced the highest mean F1-score of 0.668. By evaluating the counting results, another dataset with more than 30 000 IHC stained nuclei in 88 images were prepared. The correlation between automatically generated nucleus counting results and manual nucleus counting results was up to R2 = 0.901 (P < 0.001). By evaluating segmentation results of proposed method-based tool, we tested on a 2018 Data Science Bowl (DSB) competition dataset, three users obtained DSB score of 0.331 ± 0.006.},
  author    = {Jie Shu and Jingxin Liu and Yongmei Zhang and Hao Fu and Mohammad Ilyas and Giuseppe Faraci and Vincenzo Della Mea and Bozhi Liu and Guoping Qiu},
  doi       = {10.1093/bioinformatics/btaa107},
  issn      = {14602059},
  issue     = {10},
  journal   = {Bioinformatics},
  month     = {5},
  pages     = {3225-3233},
  pmid      = {32073624},
  publisher = {Oxford University Press},
  title     = {Marker controlled superpixel nuclei segmentation and automatic counting on immunohistochemistry staining images},
  volume    = {36},
  year      = {2020}
}
@article{Tyson2022,
  abstract  = {High-resolution whole-brain microscopy provides a means for post hoc determination of the location of implanted devices and labelled cell populations that are necessary to interpret in vivo experiments designed to understand brain function. Here we have developed two plugins (brainreg and brainreg-segment) for the Python-based image viewer napari, to accurately map any object in a common coordinate space. We analysed the position of dye-labelled electrode tracks and two-photon imaged cell populations expressing fluorescent proteins. The precise location of probes and cells were physiologically interrogated and revealed accurate segmentation with near-cellular resolution.},
  author    = {Adam L. Tyson and Mateo Vélez-Fort and Charly V. Rousseau and Lee Cossell and Chryssanthi Tsitoura and Stephen C. Lenzi and Horst A. Obenhaus and Federico Claudi and Tiago Branco and Troy W. Margrie},
  doi       = {10.1038/s41598-021-04676-9},
  issn      = {20452322},
  issue     = {1},
  journal   = {Scientific Reports},
  month     = {12},
  pmid      = {35042882},
  publisher = {Nature Research},
  title     = {Accurate determination of marker location within whole-brain microscopy images},
  volume    = {12},
  year      = {2022}
}
@inproceedings{Quinn2011,
  abstract  = {The rapid growth of human computation within research and industry has produced many novel ideas aimed at organizing web users to do great things. However, the growth is not adequately supported by a framework with which to understand each new system in the context of the old. We classify human computation systems to help identify parallels between different systems and reveal "holes" in the existing work as opportunities for new research. Since human computation is often confused with "crowdsourcing" and other terms, we explore the position of human computation with respect to these related topics. Copyright 2011 ACM.},
  author    = {Alexander J. Quinn and Benjamin B. Bederson},
  doi       = {10.1145/1978942.1979148},
  isbn      = {9781450302289},
  booktitle = {Conference on Human Factors in Computing Systems - Proceedings},
  keywords  = {Crowdsourcing,Data mining,Human computation,Literature review,Social computing,Survey,Taxonomy},
  pages     = {1403-1412},
  publisher = {Association for Computing Machinery},
  title     = {Human computation: A survey and taxonomy of a growing field},
  year      = {2011}
}
@techreport{Raykar2010,
  abstract = {For many supervised learning tasks it may be infeasible (or very expensive) to obtain objective and reliable labels. Instead, we can collect subjective (possibly noisy) labels from multiple experts or annotators. In practice, there is a substantial amount of disagreement among the annotators, and hence it is of great practical interest to address conventional supervised learning problems in this scenario. In this paper we describe a probabilistic approach for supervised learning when we have multiple annotators providing (possibly noisy) labels but no absolute gold standard. The proposed algorithm evaluates the different experts and also gives an estimate of the actual hidden labels. Experimental results indicate that the proposed method is superior to the commonly used majority voting baseline. A typical supervised learning scenario consists of a training set D = \{(x i , y i)\} N i=1 containing N instances, where x i ∈ X is an instance (typically a d-dimensional feature vector) and y i ∈ Y is the corresponding known label. The task is to learn a function f : X → Y which generalizes well on unseen data. Specifically for binary classification the supervision is from the set Y = \{0, 1\}, for multi-class classification Y = \{1,. .. , K\}, for ordinal regression Y = \{1,. .. , K\} (with an ordering 1 <. .. < K), and Y = R for regression.},
  author   = {Vikas C Raykar and Shipeng Yu and Linda H Zhao and Gerardo Hermosillo Valadez and Charles Florin and Luca Bogoni and Linda Moy and C Raykar and Gerardo H Valadez},
  journal  = {Journal of Machine Learning Research},
  keywords = {crowdsourcing,multiple annotators,multiple experts,multiple teachers},
  pages    = {1297-1322},
  title    = {Learning From Crowds 1. Supervised Learning From Multiple Annotators/Experts},
  volume   = {11},
  url      = {https://www.mturk.com.},
  year     = {2010}
}
@article{McInnes2017,
  abstract  = {HDBSCAN: Hierarchical Density-Based Spatial Clustering of Applications with Noise (Campello, Moulavi, and Sander 2013), (Campello et al. 2015). Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection. The library also includes support for Robust Single Linkage clustering (Chaudhuri et al. 2014), (Chaudhuri and Dasgupta 2010), GLOSH outlier detection (Campello et al. 2015), and tools for visualizing and exploring cluster structures. Finally support for prediction and soft clustering is also available.},
  author    = {Leland McInnes and John Healy and Steve Astels},
  doi       = {10.21105/joss.00205},
  issue     = {11},
  journal   = {The Journal of Open Source Software},
  month     = {3},
  pages     = {205},
  publisher = {The Open Journal},
  title     = {hdbscan: Hierarchical density based clustering},
  volume    = {2},
  year      = {2017}
}
@article{Endres2003,
  abstract  = {We introduce a metric for probability distributions, which is bounded, information-theoretically motivated, and has a natural Bayesian interpretation. The square root of the well-known χ2 distance is an asymptotic approximation to it. Moreover, it is a close relative of the capacitory discrimination and Jensen-Shannon divergence.},
  author    = {Dominik M. Endres and Johannes E. Schindelin},
  doi       = {10.1109/TIT.2003.813506},
  issn      = {00189448},
  issue     = {7},
  journal   = {IEEE Transactions on Information Theory},
  keywords  = {Capacitory discrimination,Jensen-Shannon divergence,Metric,Triangle inequality,χ2 distance},
  pages     = {1858-1860},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  title     = {A new metric for probability distributions},
  volume    = {49},
  year      = {2003}
}

@article{Arjovsky2017,
  abstract = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
  author   = {Martin Arjovsky and Soumith Chintala and Léon Bottou},
  month    = {12},
  title    = {Wasserstein GAN},
  url      = {http://arxiv.org/abs/1701.07875},
  year     = {2017}
}

@inproceedings{5995347,
  author    = {Torralba, Antonio and Efros, Alexei A.},
  booktitle = {CVPR 2011},
  title     = {Unbiased look at dataset bias},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {1521-1528},
  keywords  = {Visualization;Testing;Training;Object recognition;Communities;Internet;Support vector machines},
  doi       = {10.1109/CVPR.2011.5995347}
}
  
@article{DBLP:journals/corr/abs-1708-02750,
  author     = {Dim P. Papadopoulos and
                Jasper R. R. Uijlings and
                Frank Keller and
                Vittorio Ferrari},
  title      = {Extreme clicking for efficient object annotation},
  journal    = {CoRR},
  volume     = {abs/1708.02750},
  year       = {2017},
  url        = {http://arxiv.org/abs/1708.02750},
  eprinttype = {arXiv},
  eprint     = {1708.02750},
  timestamp  = {Mon, 13 Aug 2018 16:47:49 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1708-02750.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{law2022labelfreesyntheticpretrainingobject,
  title         = {Label-Free Synthetic Pretraining of Object Detectors},
  author        = {Hei Law and Jia Deng},
  year          = {2022},
  eprint        = {2208.04268},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2208.04268}
}

@article{DBLP:journals/corr/GulrajaniAADC17,
  author     = {Ishaan Gulrajani and
                Faruk Ahmed and
                Mart{\'{\i}}n Arjovsky and
                Vincent Dumoulin and
                Aaron C. Courville},
  title      = {Improved Training of Wasserstein GANs},
  journal    = {CoRR},
  volume     = {abs/1704.00028},
  year       = {2017},
  url        = {http://arxiv.org/abs/1704.00028},
  eprinttype = {arXiv},
  eprint     = {1704.00028},
  timestamp  = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/GulrajaniAADC17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{6773024,
  author   = {Shannon, C. E.},
  journal  = {The Bell System Technical Journal},
  title    = {A mathematical theory of communication},
  year     = {1948},
  volume   = {27},
  number   = {3},
  pages    = {379-423},
  keywords = {},
  doi      = {10.1002/j.1538-7305.1948.tb01338.x}
}
  
@inproceedings{5872394,
  author    = {Sommer, Christoph and Straehle, Christoph and Köthe, Ullrich and Hamprecht, Fred A.},
  booktitle = {2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro},
  title     = {Ilastik: Interactive learning and segmentation toolkit},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {230-233},
  keywords  = {Image segmentation;Biomedical imaging;Three dimensional displays;Neurons;Retina;Observers;Image color analysis;Interactive classification;image segmentation;machine learning;software tools},
  doi       = {10.1109/ISBI.2011.5872394}
}
  
@article{DBLP:journals/corr/abs-2012-07421,
  author     = {Pang Wei Koh and
                Shiori Sagawa and
                Henrik Marklund and
                Sang Michael Xie and
                Marvin Zhang and
                Akshay Balsubramani and
                Weihua Hu and
                Michihiro Yasunaga and
                Richard Lanas Phillips and
                Sara Beery and
                Jure Leskovec and
                Anshul Kundaje and
                Emma Pierson and
                Sergey Levine and
                Chelsea Finn and
                Percy Liang},
  title      = {{WILDS:} {A} Benchmark of in-the-Wild Distribution Shifts},
  journal    = {CoRR},
  volume     = {abs/2012.07421},
  year       = {2020},
  url        = {https://arxiv.org/abs/2012.07421},
  eprinttype = {arXiv},
  eprint     = {2012.07421},
  timestamp  = {Sat, 02 Jan 2021 15:43:30 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2012-07421.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/ZhuPIE17,
  author     = {Jun{-}Yan Zhu and
                Taesung Park and
                Phillip Isola and
                Alexei A. Efros},
  title      = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial
                Networks},
  journal    = {CoRR},
  volume     = {abs/1703.10593},
  year       = {2017},
  url        = {http://arxiv.org/abs/1703.10593},
  eprinttype = {arXiv},
  eprint     = {1703.10593},
  timestamp  = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/ZhuPIE17.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@proceedings{Khalid_etal,
  title     = {Artificial Neural Networks and Machine Learning – ICANN 2023: 32nd International Conference on Artificial Neural Networks, Heraklion, Crete, Greece, September 26–29, 2023, Proceedings, Part X},
  year      = {2023},
  isbn      = {978-3-031-44203-2},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  location  = {Heraklion, Greece}
}

@misc{zha2023datacentricartificialintelligencesurvey,
  title         = {Data-centric Artificial Intelligence: A Survey},
  author        = {Daochen Zha and Zaid Pervaiz Bhat and Kwei-Herng Lai and Fan Yang and Zhimeng Jiang and Shaochen Zhong and Xia Hu},
  year          = {2023},
  eprint        = {2303.10158},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2303.10158}
}

@misc{jungo2018effectinterobservervariabilityreliable,
  title         = {On the Effect of Inter-observer Variability for a Reliable Estimation of Uncertainty of Medical Image Segmentation},
  author        = {Alain Jungo and Raphael Meier and Ekin Ermis and Marcela Blatti-Moreno and Evelyn Herrmann and Roland Wiest and Mauricio Reyes},
  year          = {2018},
  eprint        = {1806.02562},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1806.02562}
}

@misc{lin2018focallossdenseobject,
  title         = {Focal Loss for Dense Object Detection},
  author        = {Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
  year          = {2018},
  eprint        = {1708.02002},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1708.02002}
}

@misc{çiçek20163dunetlearningdense,
  title         = {3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation},
  author        = {Özgün Çiçek and Ahmed Abdulkadir and Soeren S. Lienkamp and Thomas Brox and Olaf Ronneberger},
  year          = {2016},
  eprint        = {1606.06650},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1606.06650}
}

@misc{yosinski2014transferablefeaturesdeepneural,
  title         = {How transferable are features in deep neural networks?},
  author        = {Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
  year          = {2014},
  eprint        = {1411.1792},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1411.1792}
}

@article{1642623,
  author   = {von Ahn, L.},
  journal  = {Computer},
  title    = {Games with a purpose},
  year     = {2006},
  volume   = {39},
  number   = {6},
  pages    = {92-94},
  keywords = {Electrostatic precipitators;Application software;Computer vision;Internet;Labeling;Computer security;Information filtering;Information filters;Humans;Search engines;invisible computing;online games},
  doi      = {10.1109/MC.2006.196}
}
  
@misc{tremblay2018trainingdeepnetworkssynthetic,
  title         = {Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization},
  author        = {Jonathan Tremblay and Aayush Prakash and David Acuna and Mark Brophy and Varun Jampani and Cem Anil and Thang To and Eric Cameracci and Shaad Boochoon and Stan Birchfield},
  year          = {2018},
  eprint        = {1804.06516},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1804.06516}
}

@article{Checco_Bates_Demartini_2018,
  title        = {All That Glitters Is Gold — An Attack Scheme on Gold Questions in Crowdsourcing},
  volume       = {6},
  url          = {https://ojs.aaai.org/index.php/HCOMP/article/view/13332},
  doi          = {10.1609/hcomp.v6i1.13332},
  abstractnote = { &lt;p&gt; One of the most popular quality assurance mechanisms in paid micro-task crowdsourcing is based on gold questions: the use of a small set of tasks of which the requester knows the correct answer and, thus, is able to directly assess crowd work quality. In this paper, we show that such mechanism is prone to an attack carried out by a group of colluding crowd workers that is easy to implement and deploy: the inherent size limit of the gold set can be exploited by building an inferential system to detect which parts of the job are more likely to be gold questions. The described attack is robust to various forms of randomisation and programmatic generation of gold questions. We present the architecture of the proposed system, composed of a browser plug-in and an external server used to share information, and briefly introduce its potential evolution to a decentralised implementation. We implement and experimentally validate the gold detection system, using real-world data from a popular crowdsourcing platform. Finally, we discuss the economic and sociological implications of this kind of attack. &lt;/p&gt; },
  number       = {1},
  journal      = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  author       = {Checco, Alessandro and Bates, Jo and Demartini, Gianluca},
  year         = {2018},
  month        = {Jun.},
  pages        = {2-11}
}

@misc{kingma2017adammethodstochasticoptimization,
  title         = {Adam: A Method for Stochastic Optimization},
  author        = {Diederik P. Kingma and Jimmy Ba},
  year          = {2017},
  eprint        = {1412.6980},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1412.6980}
}

@inproceedings{8363766,
  author    = {Lucena, Oeslle and Souza, Roberto and Rittner, Leticia and Frayne, Richard and Lotufo, Roberto},
  booktitle = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)},
  title     = {Silver standard masks for data augmentation applied to deep-learning-based skull-stripping},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {1114-1117},
  keywords  = {Standards;Silver;Gold;Image segmentation;Training;Manuals;Biomedical imaging;Deep learning;STAPLE;Consensus;Data augmentation;silver standard masks},
  doi       = {10.1109/ISBI.2018.8363766}
}
  
@inproceedings{snow-etal-2008-cheap,
  title     = {Cheap and Fast {--} But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks},
  author    = {Snow, Rion  and
               O{'}Connor, Brendan  and
               Jurafsky, Daniel  and
               Ng, Andrew},
  editor    = {Lapata, Mirella  and
               Ng, Hwee Tou},
  booktitle = {Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing},
  month     = oct,
  year      = {2008},
  address   = {Honolulu, Hawaii},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/D08-1027/},
  pages     = {254--263}
}

@misc{goodfellow2014generativeadversarialnetworks,
  title         = {Generative Adversarial Networks},
  author        = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  year          = {2014},
  eprint        = {1406.2661},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML},
  url           = {https://arxiv.org/abs/1406.2661}
}

@article{Kuhn1955Hungarian,
  added-at  = {2011-12-12T19:01:16.000+0100},
  author    = {Kuhn, Harold W.},
  biburl    = {https://www.bibsonomy.org/bibtex/20bbf339729b509a2836d225e7dd174bb/gergie},
  doi       = {10.1002/nav.3800020109},
  file      = {:Kuhn1955Hungarian.pdf:PDF},
  groups    = {public},
  interhash = {4aaf0e5b3c9a5c33fc97d9a29b5a8f04},
  intrahash = {0bbf339729b509a2836d225e7dd174bb},
  journal   = {Naval Research Logistics Quarterly},
  keywords  = {},
  month     = {March},
  number    = {1--2},
  pages     = {83--97},
  timestamp = {2011-12-12T19:01:16.000+0100},
  title     = {{The Hungarian Method for the Assignment Problem}},
  username  = {gergie},
  volume    = 2,
  year      = 1955
}

@article{1320776d-9e76-337e-a755-73010b6e4b64,
  issn      = {00034851},
  url       = {http://www.jstor.org/stable/2236703},
  author    = {S. Kullback and R. A. Leibler},
  journal   = {The Annals of Mathematical Statistics},
  number    = {1},
  pages     = {79--86},
  publisher = {Institute of Mathematical Statistics},
  title     = {On Information and Sufficiency},
  urldate   = {2026-01-14},
  volume    = {22},
  year      = {1951}
}

@book{Kashima2016,
  author    = {鹿島, 久嗣 and 小山, 聡 and 馬場, 雪乃},
  title     = {ヒューマンコンピュテーションとクラウドソーシング = Human computation and crowdsourcing},
  publisher = {講談社},
  year      = {2016},
  series    = {MLP機械学習プロフェッショナルシリーズ},
  url       = {https://ci.nii.ac.jp/ncid/BB2107293X}
}

@inproceedings{Sommer2011,
  author    = {Sommer, Christoph and Straehle, Christoph and Köthe, Ullrich and Hamprecht, Fred A.},
  title     = {Ilastik: Interactive learning and segmentation toolkit},
  booktitle = {2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro},
  year      = {2011},
  pages     = {230--233},
  doi       = {10.1109/ISBI.2011.5872394}
}

@misc{Cicek2016,
  title         = {3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation},
  author        = {Özgün Çiçek and Ahmed Abdulkadir and Soeren S. Lienkamp and Thomas Brox and Olaf Ronneberger},
  year          = {2016},
  eprint        = {1606.06650},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1606.06650}
}

@inproceedings{Lucena2017,
  author    = {Lucena, Oeslle and Souza, Roberto and Rittner, Leticia and Frayne, Richard and Lotufo, Roberto},
  title     = {Silver standard masks for data augmentation applied to deep-learning-based skull-stripping},
  booktitle = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)},
  year      = {2018},
  pages     = {1114--1117},
  doi       = {10.1109/ISBI.2018.8363766},
  note      = {(本文中のLucena2017に対応)}
}

@misc{Jungo2018,
  title         = {On the Effect of Inter-observer Variability for a Reliable Estimation of Uncertainty of Medical Image Segmentation},
  author        = {Alain Jungo and Raphael Meier and Ekin Ermis and Marcela Blatti-Moreno and Evelyn Herrmann and Roland Wiest and Mauricio Reyes},
  year          = {2018},
  eprint        = {1806.02562},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1806.02562}
}

\% 本文が 'Willet' (tが1つ) なので、それに合わせてキーを変更
@article{Willet2013,
  author    = {Kyle W. Willett and Chris J. Lintott and Steven P. Bamford and Karen L. Masters and Brooke D. Simmons and Kevin R.V. Casteels and Edward M. Edmondson and Lucy F. Fortson and Sugata Kaviraj and William C. Keel and Thomas Melvin and Robert C. Nichol and M. Jordan Raddick and Kevin Schawinski and Robert J. Simpson and Ramin A. Skibba and Arfon M. Smith and Daniel Thomas},
  title     = {Galaxy zoo 2: Detailed morphological classifications for 304 122 galaxies from the sloan digital sky survey},
  journal   = {Monthly Notices of the Royal Astronomical Society},
  volume    = {435},
  number    = {4},
  pages     = {2835--2860},
  year      = {2013},
  publisher = {Oxford University Press}
}

@article{Zhou2019,
  title   = {Objects as points},
  author  = {Zhou, Xingyi and Wang, Dequan and Krähenbühl, Philipp},
  journal = {arXiv preprint arXiv:1904.07850},
  year    = {2019},
  url     = {https://arxiv.org/abs/1904.07850}
}

@misc{NeurIPS2021,
  title        = {NeurIPS 2021 Datasets and Benchmarks Track},
  author       = {Joaquin Vanschoren and Sai-Kit Yeung},
  year         = {2021},
  howpublished = {\url{https://neurips.cc/Conferences/2021/CallForDatasetsBenchmarks}},
  note         = {Accessed: 2026-01-15}
}

@article{Lehmann2002,
  title   = {Reference database for the comparison of automatic segmentation algorithms},
  author  = {Lehmann, Thomas M and Gönner, Carsten and Spitzer, Klaus},
  journal = {Proc. SPIE},
  volume  = {4684},
  pages   = {1588--1597},
  year    = {2002},
  note    = {(Note: Please verify if this is the intended Lehmann 2002 citation for Gold Standard discussion)}
}